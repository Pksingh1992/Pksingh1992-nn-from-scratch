{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519ac697",
   "metadata": {},
   "source": [
    "# NumPy Neural Network on Fashion-MNIST\n",
    "\n",
    "This notebook trains a small fully-connected neural network **from scratch in NumPy**\n",
    "on Fashion-MNIST (inspired by Andrew Ng's *Neural Networks and Deep Learning* Course 1).\n",
    "\n",
    "**How to use**\n",
    "1. Run the next cell to define the model (DenseNet).\n",
    "2. Run the last cell to load data and train for a few epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf206e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(z):\n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    e = np.exp(z)\n",
    "    return e / (e.sum(axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "def one_hot(y, k):\n",
    "    Y = np.zeros((len(y), k), dtype=np.float32)\n",
    "    Y[np.arange(len(y)), y] = 1.0\n",
    "    return Y\n",
    "\n",
    "class DenseNet:\n",
    "    # layers e.g. [784, 128, 64, 10]\n",
    "    def __init__(self, layers, lr=0.2, reg=1e-4, seed=42):\n",
    "        self.lr = lr; self.reg = reg\n",
    "        self.W, self.b = [], []\n",
    "        rng = np.random.default_rng(seed)\n",
    "        for i in range(len(layers)-1):\n",
    "            fan_in = layers[i]\n",
    "            w = rng.normal(0.0, np.sqrt(2.0/fan_in), size=(layers[i], layers[i+1])).astype(np.float32)\n",
    "            b = np.zeros(layers[i+1], dtype=np.float32)\n",
    "            self.W.append(w); self.b.append(b)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.a = [X.astype(np.float32)]\n",
    "        self.z = []\n",
    "        for i in range(len(self.W)):\n",
    "            z = self.a[-1] @ self.W[i] + self.b[i]\n",
    "            self.z.append(z)\n",
    "            if i < len(self.W)-1:\n",
    "                a = np.maximum(0.0, z)   # ReLU\n",
    "            else:\n",
    "                a = softmax(z)           # final softmax\n",
    "            self.a.append(a)\n",
    "        return self.a[-1]\n",
    "\n",
    "    def loss_ce(self, Y_true, P):\n",
    "        ce = -np.mean(np.sum(Y_true * np.log(P + 1e-9), axis=1))\n",
    "        l2 = 0.5 * self.reg * sum((w*w).sum() for w in self.W)\n",
    "        return ce + l2\n",
    "\n",
    "    def backward(self, Y_true):\n",
    "        grads_W = [None]*len(self.W)\n",
    "        grads_B = [None]*len(self.b)\n",
    "        m = Y_true.shape[0]\n",
    "        delta = (self.a[-1] - Y_true) / m\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            a_prev = self.a[i]\n",
    "            grads_W[i] = (a_prev.T @ delta) + self.reg * self.W[i]\n",
    "            grads_B[i] = delta.sum(axis=0)\n",
    "            if i > 0:\n",
    "                delta = (delta @ self.W[i].T) * (a_prev > 0)\n",
    "        return grads_W, grads_B\n",
    "\n",
    "    def step(self, gW, gB):\n",
    "        for i in range(len(self.W)):\n",
    "            self.W[i] -= self.lr * gW[i]\n",
    "            self.b[i] -= self.lr * gB[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST, train for 3 epochs, and report test accuracy\n",
    "import numpy as np, time\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# data\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train = (X_train.astype(\"float32\")/255.0).reshape(len(X_train), 784)\n",
    "X_test  = (X_test.astype(\"float32\")/255.0).reshape(len(X_test), 784)\n",
    "\n",
    "# model\n",
    "def one_hot(y, k):\n",
    "    Y = np.zeros((len(y), k), dtype=np.float32)\n",
    "    Y[np.arange(len(y)), y] = 1.0\n",
    "    return Y\n",
    "\n",
    "model = DenseNet([784,128,64,10], lr=0.2, reg=1e-4)\n",
    "Y_train = one_hot(y_train, 10)\n",
    "\n",
    "def acc(m, X, y, bs=2048):\n",
    "    ok=0\n",
    "    for i in range(0,len(X),bs):\n",
    "        p = m.forward(X[i:i+bs]).argmax(1)\n",
    "        ok += int((p==y[i:i+bs]).sum())\n",
    "    return ok/len(X)\n",
    "\n",
    "batch = 256\n",
    "for ep in range(1, 4):\n",
    "    perm = np.random.permutation(len(X_train))\n",
    "    X_train, Y_train = X_train[perm], Y_train[perm]\n",
    "    for i in range(0, len(X_train), batch):\n",
    "        xb = X_train[i:i+batch]; yb = Y_train[i:i+batch]\n",
    "        P = model.forward(xb)\n",
    "        gW, gB = model.backward(yb)\n",
    "        model.step(gW, gB)\n",
    "    print(f\"Epoch {ep:02d} | test_acc={acc(model, X_test, y_test):.3f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
